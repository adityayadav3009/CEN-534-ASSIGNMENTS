{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy import matmul\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import f as  f_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bo =  4.799003322259182  , B1 =  0.5946843853820593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Y')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array([90,86,67,89,81,75])\n",
    "y = np.array([62,45,40,55,64,53])\n",
    "a = 0 \n",
    "b = 0\n",
    "def linear_reg(x , y ) :\n",
    "     n = len(x)\n",
    "     b = (sum(x*y)- n*x.mean()*y.mean() ) /(sum(x*x) - n*pow(x.mean(),2))\n",
    "     a = y.mean() - b*x.mean()\n",
    "     return [a , b]\n",
    "a , b = linear_reg(x , y  )\n",
    "print(\"Bo = \",a,\" , B1 = \" , b)\n",
    "plt.scatter(x , y)\n",
    "plt.plot(x , a + b*x)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bo =  49.16408268733792  , B1 =  0.07881136950905085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Y')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#if (67 ,40 ) removed \n",
    "x_ = np.array([90,86,89,81,75])\n",
    "y_ = np.array([62,45,55,64,53])\n",
    "a_ = 0 \n",
    "b_ = 0\n",
    "def linear_reg(x , y ) :\n",
    "     n = len(x)\n",
    "     b = (sum(x*y)- n*x.mean()*y.mean() ) /(sum(x*x) - n*pow(x.mean(),2))\n",
    "     a = y.mean() - b*x.mean()\n",
    "     return [a , b]\n",
    "a_ , b_ = linear_reg(x_ , y_  )\n",
    "print(\"Bo = \",a_,\" , B1 = \" , b_)\n",
    "plt.scatter(x_ , y_)\n",
    "plt.plot(x_ , a_ + b_*x_)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.1312292358804"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y--> heart rate , X --> weight\n",
    "# for Weight = 88\n",
    "heart_rate = a + b*88\n",
    "heart_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = np.array([ 324 , 226 , 1474 , 2142 ,420 , 45 , 38 , 363 ,77 , 84 , 46 , 38 ])\n",
    "rainfall = np.array([ 43 ,53 ,48 ,50 ,43 ,61 , 81 , 68 ,74 , 71 , 71 , 69])\n",
    "discharge = np.array([0.44 , .24 ,2.41 , 2.97 , 0.7 ,.11 ,0.05 , 0.51 , 0.25 , 0.23 , 0.1 , 0.054])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.ones(12) ,area , rainfall ]).T \n",
    "# Adding ones in matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 3.240e+02, 4.300e+01],\n",
       "       [1.000e+00, 2.260e+02, 5.300e+01],\n",
       "       [1.000e+00, 1.474e+03, 4.800e+01],\n",
       "       [1.000e+00, 2.142e+03, 5.000e+01],\n",
       "       [1.000e+00, 4.200e+02, 4.300e+01],\n",
       "       [1.000e+00, 4.500e+01, 6.100e+01],\n",
       "       [1.000e+00, 3.800e+01, 8.100e+01],\n",
       "       [1.000e+00, 3.630e+02, 6.800e+01],\n",
       "       [1.000e+00, 7.700e+01, 7.400e+01],\n",
       "       [1.000e+00, 8.400e+01, 7.100e+01],\n",
       "       [1.000e+00, 4.600e+01, 7.100e+01],\n",
       "       [1.000e+00, 3.800e+01, 6.900e+01]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X   # 12*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "a , b , c = inv(X.T @ X) @ X.T @ Y.T # Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score = 1 - ( sum(np.square(discharge - (a+b*area+c*rainfall))) / sum(np.square(discharge - discharge.mean()))  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9875054096536013"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.006</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.006</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.7</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.006</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.021</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.5</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.021</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.021</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.4</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.005</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.005</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.5</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.005</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.008</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.008</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.60</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.008</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.023</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.023</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.023</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.023</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.023</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.023</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.75</td>\n",
       "      <td>6.0</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.00</td>\n",
       "      <td>0.039</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15</td>\n",
       "      <td>67</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.00</td>\n",
       "      <td>0.039</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15</td>\n",
       "      <td>67</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.00</td>\n",
       "      <td>0.039</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15</td>\n",
       "      <td>67</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.00</td>\n",
       "      <td>0.109</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15</td>\n",
       "      <td>62</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.00</td>\n",
       "      <td>0.109</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15</td>\n",
       "      <td>62</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.00</td>\n",
       "      <td>0.109</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15</td>\n",
       "      <td>62</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.00</td>\n",
       "      <td>0.055</td>\n",
       "      <td>6.5</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.00</td>\n",
       "      <td>0.055</td>\n",
       "      <td>6.5</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.00</td>\n",
       "      <td>0.055</td>\n",
       "      <td>6.5</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.25</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.00</td>\n",
       "      <td>0.055</td>\n",
       "      <td>6.5</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.00</td>\n",
       "      <td>0.055</td>\n",
       "      <td>6.5</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.00</td>\n",
       "      <td>0.055</td>\n",
       "      <td>6.5</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.76</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1     X2    X3  X4  X5   X6    X7    X8   X9     Q\n",
       "0   0.03  0.006   3.0   1  70  1.5  0.25  1.75  2.0    46\n",
       "1   0.03  0.006   3.0   1  70  1.5  0.25  2.25  3.7    28\n",
       "2   0.03  0.006   3.0   1  70  1.5  0.25  4.00  4.2    54\n",
       "3   0.03  0.021   3.0   1  80  1.0  0.25  1.60  1.5    70\n",
       "4   0.03  0.021   3.0   1  80  1.0  0.25  3.10  4.0    47\n",
       "5   0.03  0.021   3.0   1  80  1.0  0.25  3.60  2.4   112\n",
       "6   0.13  0.005   6.5   2  65  2.0  0.35  1.25  0.7   398\n",
       "7   0.13  0.005   6.5   2  65  2.0  0.35  2.30  3.5    98\n",
       "8   0.13  0.005   6.5   2  65  2.0  0.35  4.25  4.0   191\n",
       "9   0.13  0.008   6.5   2  68  0.5  0.15  1.45  2.0   171\n",
       "10  0.13  0.008   6.5   2  68  0.5  0.15  2.60  4.0   150\n",
       "11  0.13  0.008   6.5   2  68  0.5  0.15  3.90  3.0   331\n",
       "12  1.00  0.023  15.0  10  60  1.0  0.20  0.75  1.0   772\n",
       "13  1.00  0.023  15.0  10  60  1.0  0.20  1.75  1.5  1268\n",
       "14  1.00  0.023  15.0  10  60  1.0  0.20  3.25  4.0   849\n",
       "15  1.00  0.023  15.0  10  65  2.0  0.20  1.80  1.0  2294\n",
       "16  1.00  0.023  15.0  10  65  2.0  0.20  3.10  2.0  1984\n",
       "17  1.00  0.023  15.0  10  65  2.0  0.20  4.75  6.0   900\n",
       "18  3.00  0.039   7.0  15  67  0.5  0.50  1.75  2.0  2181\n",
       "19  3.00  0.039   7.0  15  67  0.5  0.50  3.25  4.0  2484\n",
       "20  3.00  0.039   7.0  15  67  0.5  0.50  5.00  6.5  2450\n",
       "21  5.00  0.109   6.0  15  62  1.5  0.60  1.50  1.5  1794\n",
       "22  5.00  0.109   6.0  15  62  1.5  0.60  2.75  3.0  2067\n",
       "23  5.00  0.109   6.0  15  62  1.5  0.60  4.20  5.0  2586\n",
       "24  7.00  0.055   6.5  19  56  2.0  0.50  1.80  2.0  2410\n",
       "25  7.00  0.055   6.5  19  56  2.0  0.50  3.25  4.0  1808\n",
       "26  7.00  0.055   6.5  19  56  2.0  0.50  5.25  6.0  3024\n",
       "27  7.00  0.055   6.5  19  56  1.0  0.50  1.25  2.0   710\n",
       "28  7.00  0.055   6.5  19  56  1.0  0.50  2.90  3.4  3181\n",
       "29  7.00  0.055   6.5  19  56  1.0  0.50  4.76  5.0  4279"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"q3_tut1.xlsx\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_data = data \n",
    "ln_data = ln_data.applymap(lambda x  : np.log(x))\n",
    "ln_data.columns = [\"ln \" + a for a in ln_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ln_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ln X1</th>\n",
       "      <th>ln X2</th>\n",
       "      <th>ln X3</th>\n",
       "      <th>ln X4</th>\n",
       "      <th>ln X5</th>\n",
       "      <th>ln X6</th>\n",
       "      <th>ln X7</th>\n",
       "      <th>ln X8</th>\n",
       "      <th>ln X9</th>\n",
       "      <th>ln Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.506558</td>\n",
       "      <td>-5.115996</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.248495</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.559616</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.828641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.506558</td>\n",
       "      <td>-5.115996</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.248495</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.810930</td>\n",
       "      <td>1.308333</td>\n",
       "      <td>3.332205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.506558</td>\n",
       "      <td>-5.115996</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.248495</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.435085</td>\n",
       "      <td>3.988984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.506558</td>\n",
       "      <td>-3.863233</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.382027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.470004</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>4.248495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.506558</td>\n",
       "      <td>-3.863233</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.382027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1.131402</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>3.850148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ln X1     ln X2     ln X3  ln X4     ln X5     ln X6     ln X7  \\\n",
       "0 -3.506558 -5.115996  1.098612    0.0  4.248495  0.405465 -1.386294   \n",
       "1 -3.506558 -5.115996  1.098612    0.0  4.248495  0.405465 -1.386294   \n",
       "2 -3.506558 -5.115996  1.098612    0.0  4.248495  0.405465 -1.386294   \n",
       "3 -3.506558 -3.863233  1.098612    0.0  4.382027  0.000000 -1.386294   \n",
       "4 -3.506558 -3.863233  1.098612    0.0  4.382027  0.000000 -1.386294   \n",
       "\n",
       "      ln X8     ln X9      ln Q  \n",
       "0  0.559616  0.693147  3.828641  \n",
       "1  0.810930  1.308333  3.332205  \n",
       "2  1.386294  1.435085  3.988984  \n",
       "3  0.470004  0.405465  4.248495  \n",
       "4  1.131402  1.386294  3.850148  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ln_data.drop(\"ln Q\",axis = 1)\n",
    "X[\"ln X0\"] = np.ones(30)\n",
    "Y = ln_data[\"ln Q\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_lin_reg( X , Y ,to_be_dropped) :\n",
    "     print(\"\\n....................................................\\n\")\n",
    "     print(\"DROPPED -->\",\" ,\".join(to_be_dropped))\n",
    "     train = X \n",
    "     for clm in to_be_dropped :\n",
    "          train = train.drop(clm , axis  = 1 )\n",
    "     df_total =  len(train)-1\n",
    "     df_reg =  len(train.columns)-1\n",
    "     df_residual = df_total - df_reg\n",
    "     Fo = f_score.ppf(1-0.05,df_reg,df_residual)\n",
    "     # print(\"degrees of freedom ,\",df_total, \",\",df_reg ,\",\", df_residual) \n",
    "     train = np.array(train).T\n",
    "     Y = np.array(Y)\n",
    "     betas = inv(train @ train.T ) @ train @Y\n",
    "     SSE = sum(np.square(betas@train-Y))\n",
    "     SSR = sum(np.square(betas@train-Y.mean())) \n",
    "     SST = sum(np.square(Y-Y.mean()))\n",
    "     MSE = SSE/df_residual\n",
    "     print(\"_________  df _____ SS _________ MS\")\n",
    "     print(\"Total      {0}       {1:.2f}       \".format(df_total , SST ) )\n",
    "     print(\"Regression {0}       {1:.2f}       {2:.2f}\".format(df_reg , SSR,SSR/df_reg ) )\n",
    "     print(\"Residual   {0}       {1:.2f}       {2:.2f}\".format(df_residual , SSE ,MSE) )\n",
    "     return betas , SSE , SSR , SST ,MSE ,Fo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> \n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 9       70.46       7.83\n",
      "Residual   20       0.93       0.05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.58784567, -0.09845931,  0.30818817,  0.33136547,  1.40256679,\n",
       "       -0.27356153,  0.07480784,  1.63582172, -1.395186  , -0.73312778])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas , _ ,_ ,_ ,_ ,_ = mult_lin_reg(X , Y , [])\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________\n",
      "\n",
      "ITERATION : 1\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> \n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 9       70.46       7.83\n",
      "Residual   20       0.93       0.05\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X1\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 8       70.20       8.77\n",
      "Residual   21       1.19       0.06\n",
      "F Value ::  5.6529552283196045\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X2\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 8       70.44       8.80\n",
      "Residual   21       0.95       0.05\n",
      "F Value ::  0.5055024448187606\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X3\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 8       70.40       8.80\n",
      "Residual   21       0.99       0.05\n",
      "F Value ::  1.3237453209670829\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X4\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 8       70.43       8.80\n",
      "Residual   21       0.96       0.05\n",
      "F Value ::  0.7452183395635671\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X5\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 8       70.41       8.80\n",
      "Residual   21       0.98       0.05\n",
      "F Value ::  1.0894795837573172\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X6\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 8       70.23       8.78\n",
      "Residual   21       1.16       0.06\n",
      "F Value ::  4.905337603612783\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 8       70.46       8.81\n",
      "Residual   21       0.93       0.04\n",
      "F Value ::  0.08231608300067154\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X8\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 8       66.83       8.35\n",
      "Residual   21       4.56       0.22\n",
      "F Value ::  78.1710184310236\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X9\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 8       66.99       8.37\n",
      "Residual   21       4.40       0.21\n",
      "F Value ::  74.68387602815226\n",
      "\n",
      "\n",
      "Minimum  F value =  0.08231608300067154\n",
      "\n",
      "Critical F value =  2.4204621973544547\n",
      "\n",
      "Remove  ln X7\n",
      "_______________________________________________\n",
      "\n",
      "ITERATION : 2\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 8       70.46       8.81\n",
      "Residual   21       0.93       0.04\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X1\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 7       70.07       10.01\n",
      "Residual   22       1.32       0.06\n",
      "F Value ::  8.770757579499184\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X2\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 7       70.41       10.06\n",
      "Residual   22       0.98       0.04\n",
      "F Value ::  1.0636351450357702\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X3\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 7       70.37       10.05\n",
      "Residual   22       1.02       0.05\n",
      "F Value ::  1.9733436523957961\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 7       70.42       10.06\n",
      "Residual   22       0.97       0.04\n",
      "F Value ::  0.7776525821823347\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X5\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 7       70.37       10.05\n",
      "Residual   22       1.03       0.05\n",
      "F Value ::  2.1101998588542776\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X6\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 7       70.15       10.02\n",
      "Residual   22       1.24       0.06\n",
      "F Value ::  6.912916437447855\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X7\n",
      ".....not possible\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X8\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 7       66.80       9.54\n",
      "Residual   22       4.60       0.21\n",
      "F Value ::  82.34871007983051\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X9\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 7       66.99       9.57\n",
      "Residual   22       4.40       0.20\n",
      "F Value ::  78.01114958827634\n",
      "\n",
      "\n",
      "Minimum  F value =  0.7776525821823347\n",
      "\n",
      "Critical F value =  2.463773829960808\n",
      "\n",
      "Remove  ln X4\n",
      "_______________________________________________\n",
      "\n",
      "ITERATION : 3\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 7       70.42       10.06\n",
      "Residual   22       0.97       0.04\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X1\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 6       66.78       11.13\n",
      "Residual   23       4.61       0.20\n",
      "F Value ::  82.841072144327\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 6       70.39       11.73\n",
      "Residual   23       1.00       0.04\n",
      "F Value ::  0.6981607776139841\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X3\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 6       69.88       11.65\n",
      "Residual   23       1.51       0.07\n",
      "F Value ::  12.253242238091325\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X4\n",
      ".....not possible\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X5\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 6       70.29       11.72\n",
      "Residual   23       1.10       0.05\n",
      "F Value ::  2.9963523163037395\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X6\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 6       70.13       11.69\n",
      "Residual   23       1.26       0.05\n",
      "F Value ::  6.603979961372812\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X7\n",
      ".....not possible\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X8\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 6       66.79       11.13\n",
      "Residual   23       4.60       0.20\n",
      "F Value ::  82.50839672139377\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X9\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 6       66.98       11.16\n",
      "Residual   23       4.41       0.19\n",
      "F Value ::  78.23291371704926\n",
      "\n",
      "\n",
      "Minimum  F value =  0.6981607776139841\n",
      "\n",
      "Critical F value =  2.5276553252421783\n",
      "\n",
      "Remove  ln X2\n",
      "_______________________________________________\n",
      "\n",
      "ITERATION : 4\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 6       70.39       11.73\n",
      "Residual   23       1.00       0.04\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X1\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 5       52.83       10.57\n",
      "Residual   24       18.56       0.77\n",
      "F Value ::  404.27787506512715\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X2\n",
      ".....not possible\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X3\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 5       69.57       13.91\n",
      "Residual   24       1.82       0.08\n",
      "F Value ::  18.998354459982963\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X4\n",
      ".....not possible\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X5\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 5       70.28       14.06\n",
      "Residual   24       1.11       0.05\n",
      "F Value ::  2.502678858188707\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X6\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 5       70.01       14.00\n",
      "Residual   24       1.38       0.06\n",
      "F Value ::  8.759831249945034\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X7\n",
      ".....not possible\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X8\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 5       66.66       13.33\n",
      "Residual   24       4.73       0.20\n",
      "F Value ::  85.88500866007081\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X9\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 5       66.94       13.39\n",
      "Residual   24       4.45       0.19\n",
      "F Value ::  79.53997481882723\n",
      "\n",
      "\n",
      "Minimum  F value =  2.502678858188707\n",
      "\n",
      "Critical F value =  2.620654147862887\n",
      "\n",
      "Remove  ln X5\n",
      "_______________________________________________\n",
      "\n",
      "ITERATION : 5\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X5\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 5       70.28       14.06\n",
      "Residual   24       1.11       0.05\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X5 ,ln X1\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 4       31.29       7.82\n",
      "Residual   25       40.10       1.60\n",
      "F Value ::  844.8917199965267\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X5 ,ln X2\n",
      ".....not possible\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X5 ,ln X3\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 4       69.56       17.39\n",
      "Residual   25       1.83       0.07\n",
      "F Value ::  15.640374188749282\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X5 ,ln X4\n",
      ".....not possible\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X5 ,ln X5\n",
      ".....not possible\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X5 ,ln X6\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 4       69.50       17.38\n",
      "Residual   25       1.89       0.08\n",
      "F Value ::  16.97287703665894\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X5 ,ln X7\n",
      ".....not possible\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X5 ,ln X8\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 4       65.40       16.35\n",
      "Residual   25       5.99       0.24\n",
      "F Value ::  105.83591185447928\n",
      "\n",
      "....................................................\n",
      "\n",
      "DROPPED --> ln X7 ,ln X4 ,ln X2 ,ln X5 ,ln X9\n",
      "_________  df _____ SS _________ MS\n",
      "Total      29       71.39       \n",
      "Regression 4       65.92       16.48\n",
      "Residual   25       5.47       0.22\n",
      "F Value ::  94.60779485762606\n",
      "\n",
      "\n",
      "Minimum  F value =  15.640374188749282\n",
      "\n",
      "Critical F value =  2.758710469717632\n",
      "\n",
      "\n",
      "TO BE DROPPED  ['ln X7', 'ln X4', 'ln X2', 'ln X5']\n"
     ]
    }
   ],
   "source": [
    "initial_drop = []\n",
    "iteration = 1\n",
    "while True :\n",
    "     print(\"_______________________________________________\\n\")\n",
    "     print(\"ITERATION :\" ,iteration)\n",
    "     iteration+=1\n",
    "     _ ,SSE_full , SSR_full , SST_full , MSE_full ,_=   mult_lin_reg(X,Y,initial_drop)\n",
    "     list_F_scores = []\n",
    "     minimum_f_val = 1000000 \n",
    "     selected_clm = \"\"\n",
    "     for clm in ['ln X1' , 'ln X2', 'ln X3', 'ln X4', 'ln X5', 'ln X6', 'ln X7', 'ln X8', 'ln X9'] :\n",
    "          try :\n",
    "               initial_drop.append(clm)     \n",
    "               _ ,SSE_removed , SSR_removed , SST_removed , MSE_removed ,Fo=   mult_lin_reg(X,Y,initial_drop)\n",
    "               initial_drop.pop()\n",
    "               F_score = (SSR_full - SSR_removed)/MSE_full\n",
    "               if F_score < minimum_f_val :\n",
    "                    minimum_f_val = F_score\n",
    "                    selected_clm = clm\n",
    "               print(\"F Value :: \",F_score)\n",
    "               list_F_scores.append(F_score)\n",
    "          except :\n",
    "               initial_drop.pop()\n",
    "               print(\".....not possible\")\n",
    "               continue\n",
    "\n",
    "     print(\"\\n\\nMinimum  F value = \" ,minimum_f_val )\n",
    "     print(\"\\nCritical F value = \" ,Fo )\n",
    "     if Fo > minimum_f_val :\n",
    "          print(\"\\nRemove \",selected_clm)\n",
    "          initial_drop.append(selected_clm)\n",
    "     else :\n",
    "          break \n",
    "print(\"\\n\\nTO BE DROPPED \", initial_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f1895313fe779cc7cc3618b197f790529e13cb16f59b29ecbf325dee8d29830"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
